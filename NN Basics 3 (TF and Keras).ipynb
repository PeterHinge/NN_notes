{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of neural networks 3 (TensorFlow and Keras)\n",
    "\n",
    "### Making neural nets using TensorFlow and Keras\n",
    "\n",
    "This notebook is a follow up to my NN Basics 2. This time we use TensorFlow and the Keras API that sits atop TensorFlow. TensorFlow is probably the most well-known machine learning module for enthusiasts and for good reason, since it allows even beginners to make various type of well working neural networks.\n",
    "\n",
    "Time this we do need certain libraries/extensions that is not native to python. For now we only need TensorFlow and Keras along with Matplotlib for graphical visualization. There are many guides on how to install libraries on the internet. Here are my recommended versions (you might get away with other versions but these work for sure).\n",
    "\n",
    "### Versions (recommended):\n",
    "<ul>\n",
    "  <li>Python 3.6</li>\n",
    "  <li>TensorFlow 1.14.0</li>\n",
    "  <li>Keras 2.2.4</li>\n",
    "  <li>Matplotlib 3.1.0</li>    \n",
    "</ul>\n",
    "\n",
    "First we make the relevant imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our neural net, we will be using a data set called \"mnist\", which is kind of the world of ML's equivalent to \"hello world\" (maybe you have even seen it before if you have practiced clustering etc.). In short, the data set is a collection of 28x28 binary-pixel pictures of handwritten digits and there corresponding value.\n",
    "\n",
    "Let's first get a feel for the data. We load the mnist data set and use matplotlib to display the first training sample and print the target value or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "label = y_train[0]\n",
    "print(\"Label: \" + str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the first sample is a 5. The data is divided into a training set (which of course is used for training) and a testing set (which is used for model validation). But before we proceed with our model creation, we need to normalize our data. Normally pixel values are between 0 and 255, however neural perform better on data between 0 and 1. Furthermore our data is in integers and we want it in floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the normalizing changes our data display slightly.\n",
    "\n",
    "Next, it is time to build our model and train it. In TensorFlow the model creation and training process is as follows:\n",
    "<ol>\n",
    "  <li>Create model structure</li>\n",
    "  <li>Compile model</li>\n",
    "  <li>Fit the model to the data (training)</li>\n",
    "  <li>Evaluate the model</li>\n",
    "  <li>Make predictions based on the the model</li> \n",
    "</ol>\n",
    "\n",
    "The structural step is very similar to the one we saw in NN Basics 2 - here I have created a DNN with 3 hidden layers (128, 256 and 128 neurons). The only difference is initial flattening layer along with a specification of the input shape, which makes small improvements to our networks overall performance. \n",
    "\n",
    "In the compiling step, we choose \"how\" our network learns, i.e. the optimizer, the way of measuring loss etc. If you seek a career in AI and ML, I would recommend that you actually learn what these are and how they work. <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\">Here</a> is a link to TensorFlow's optimizers, which is a good place to start. \n",
    "\n",
    "In the fitting step the model is fed the data for a number of epochs (iterations), here I picked 3.\n",
    "\n",
    "The evaluation step returns the validation loss and accuracy, so we can check for over-fitting (more on that later).\n",
    "\n",
    "Finally we can make predictions based on our trained model. The evaluation step is not necessary in order to make predictions, seeing and the model acts like an object, but evaluation step is a good indicator of our networks ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2422 - acc: 0.9252\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1013 - acc: 0.9683\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0700 - acc: 0.9781\n",
      "Evaluating:\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.0935 - acc: 0.9721\n",
      "Prediction:\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()  # model structure\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape= x_train.shape[1:]))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',  # model compiling\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training:')\n",
    "model.fit(x_train, y_train, epochs=3)  # model training\n",
    "\n",
    "print('Evaluating:')\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  # model evaluation\n",
    "\n",
    "print('Prediction:')\n",
    "predictions = model.predict(x_test)  # model predictions\n",
    "print(np.argmax(predictions[0]))\n",
    "\n",
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our model made the right prediction.\n",
    "\n",
    "A significant challenge with neural nets is the issue of \"over-fitting\". In short, this means that the model ends up simply memorizing the training data as suppose to finding general patterns and thus the model is really good predicting in-training-samples but not good at predicting out-of-training-samples. This is where the evaluation step becomes really valuable. Of course we would expect our model to be a little more precise on in-training-samples, however, it should be almost as good for the out-of-training-samples. Our model seems not to have over-fitted (loss: 0.0700 - acc: 0.9781 vs val_loss: 0.0935 - val_acc: 0.9721), but how do we make sure and more importantly how do we find the most optimal parameters for a given task? Here are some things worth considering:\n",
    "<ul>\n",
    "  <li>Optimal number of layers</li>\n",
    "  <li>Optimal number of neurons in layers</li>\n",
    "  <li>Optimal number of epoch</li>\n",
    "  <li>Optimal compiling parameters</li> \n",
    "</ul>\n",
    "\n",
    "### Using Keras and TensorBoard \n",
    "TensorBoard is an excellent way to evaluate and compare the which parameters are optimal for a given problem. TensorBoard creates a separate folder of the training results that can be displayed and inspected. Here we are gonna make basically the same model as before, but we are going to run it for 10 epochs to see if we can figure out the optimal number of epochs. We will also be using concrete imports straight from keras (the same can be achieved by using tf.keras.XXXXXX). Notice how this makes our model look more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 7s 163us/step - loss: 0.2839 - acc: 0.9129 - val_loss: 0.1495 - val_acc: 0.9552\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 0.1152 - acc: 0.9638 - val_loss: 0.1271 - val_acc: 0.9627\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 6s 148us/step - loss: 0.0771 - acc: 0.9752 - val_loss: 0.1286 - val_acc: 0.9622\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.0581 - acc: 0.9819 - val_loss: 0.1052 - val_acc: 0.9684\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 6s 148us/step - loss: 0.0445 - acc: 0.9854 - val_loss: 0.1241 - val_acc: 0.9671\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.0357 - acc: 0.9886 - val_loss: 0.1341 - val_acc: 0.9658\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 6s 150us/step - loss: 0.0301 - acc: 0.9898 - val_loss: 0.1254 - val_acc: 0.9691\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 6s 148us/step - loss: 0.0251 - acc: 0.9921 - val_loss: 0.1502 - val_acc: 0.9663\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 6s 154us/step - loss: 0.0230 - acc: 0.9924 - val_loss: 0.1366 - val_acc: 0.9701\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 0.0219 - acc: 0.9927 - val_loss: 0.1539 - val_acc: 0.9659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25119cf0278>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu, input_shape= x_train.shape[1:]))\n",
    "model.add(Dense(256, activation=tf.nn.relu))\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "model.compile(optimizer='adam',  \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data can then be viewed graphically with TensorBoard although I can't show it in Jupyter Notebook, but we can see that the val_loss breaks off after the 4th epoch, which can be a good indicator that the optimal number of epoch is 4. We could also change other parameters and compare everything and TensorBoard makes such a compassion much more manageable.\n",
    "\n",
    "In these first 3 notebooks, we have only used regular ANNs and DNNs, however, mastering the TensorFlow basics truly opens the would of machine learning to you, including CNNs (Convolutional Neural Networks), RNNs (Recurrent Neural Networks), reinforcement learning, image and video recognition and so much more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
